# web_ui.py
import os
import re
import shutil
import gradio as gr
from PIL import Image
import modules.llm as llm

from modules.pdf_parser import parse_pdf
from modules.text_encoder import embed_text
from modules.image_encoder import embed_image
from modules.classifier import classify_paper
from config import PAPER_DIR, IMAGE_DIR, DEEPSEEK_API_KEY # â­ å¯¼å…¥ Key
from modules.time_parser import TimeParser # â­ å¯¼å…¥ä½ åˆšæ‰æ–°å»ºçš„è§£æå™¨

tp = TimeParser(api_key=DEEPSEEK_API_KEY)

from modules.search import (
    add_paper_embedding,
    add_paragraph,
    search_paper,
    search_paragraph,
    add_image_embedding,
    search_image_visual,
    search_image_text,
    image_visual_col,  # è§†è§‰åº“ (CLIP)
    image_text_col     # æ–‡æœ¬åº“ (BGE)
)

from modules.paragraph_splitter import split_paragraphs

# =====================
# å…¨å±€é…ç½®
# =====================
# ä½¿ç”¨ config.py ä¸­çš„é…ç½®ï¼Œç¡®ä¿è·¯å¾„ä¸€è‡´
PAPER_ROOT = PAPER_DIR
IMAGE_ROOT = IMAGE_DIR

os.makedirs(PAPER_ROOT, exist_ok=True)
os.makedirs(IMAGE_ROOT, exist_ok=True)

# =====================
# è®ºæ–‡æ·»åŠ ï¼ˆå«æ®µè½ç´¢å¼•ï¼‰
# =====================
def ui_add_paper(pdf_path, topics):
    if not pdf_path:
        return "âŒ è¯·ä¸Šä¼  PDF æ–‡ä»¶"

    topics = [t.strip() for t in topics.split(',') if t.strip()]
    if not topics:
        return "âŒ è¯·æä¾›å€™é€‰ä¸»é¢˜"

    try:
        text = parse_pdf(pdf_path)
        if len(text) < 200:
            return "âŒ PDF è§£æå¤±è´¥æˆ–å†…å®¹è¿‡çŸ­"
    except Exception as e:
        return f"âŒ PDF è§£æå¤±è´¥: {str(e)}"

    # LLM åˆ†ç±»
    try:
        topic = classify_paper(text, topics)
    except Exception as e:
        return f"âŒ åˆ†ç±»å¤±è´¥: {str(e)}"

    pid = os.path.basename(pdf_path)

    # æ–‡æ¡£çº§ embedding
    try:
        doc_emb = embed_text(text)
        add_paper_embedding(
            pid=pid,
            embedding=doc_emb,
            metadata={
                "paper": pid,
                "topic": topic,
                "path": pdf_path  # æ·»åŠ è·¯å¾„ä¿¡æ¯
            }
        )
    except Exception as e:
        return f"âŒ æ·»åŠ è®ºæ–‡å‘é‡å¤±è´¥: {str(e)}"

    # æ®µè½ç´¢å¼•
    try:
        paragraphs = split_paragraphs(text)
        for i, para in enumerate(paragraphs):
            p_emb = embed_text(para)
            add_paragraph(
                pid=pid,
                para_id=i,
                embedding=p_emb,
                metadata={
                    "paper": pid,
                    "topic": topic,
                    "text": para
                }
            )
    except Exception as e:
        return f"âŒ æ®µè½ç´¢å¼•å¤±è´¥: {str(e)}"

    # ===== æ–‡ä»¶ä¿å­˜åˆ°ä¸»é¢˜ç›®å½• =====
    try:
        target_dir = os.path.join(PAPER_ROOT, topic)
        os.makedirs(target_dir, exist_ok=True)
        target_path = os.path.join(target_dir, pid)
        
        # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(target_path):
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå¯ä»¥é€‰æ‹©è¦†ç›–æˆ–è·³è¿‡
            # è¿™é‡Œé€‰æ‹©è¦†ç›–
            pass
        
        # å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
        shutil.copy(pdf_path, target_path)
    except Exception as e:
        return f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}\nâœ… å‘é‡å·²æ·»åŠ ï¼Œä½†æ–‡ä»¶ä¿å­˜å¤±è´¥"

    return f"âœ… å·²æ·»åŠ è®ºæ–‡ï¼š{pid}\nğŸ“‚ åˆ†ç±»ä¸»é¢˜ï¼š{topic}\nğŸ“‘ æ®µè½æ•°ï¼š{len(paragraphs)}\nğŸ’¾ ä¿å­˜è·¯å¾„ï¼š{target_path}"

# =====================
# è®ºæ–‡è¯­ä¹‰æœç´¢
# =====================
def ui_search_paper(query):
    emb = embed_text(query)
    results = search_paper(emb)

    if not results or not results.get("metadatas") or not results["metadatas"]:
        return "âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡"
    
    # ä» metadatas ä¸­æå–ä¿¡æ¯
    output = []
    for meta in results["metadatas"][0]:
        paper = meta.get("paper") or meta.get("path", "unknown")
        topic = meta.get("topic", "unknown")
        output.append(f"ğŸ“„ {paper}  (topic={topic})")
    
    return "\n".join(output)

# =====================
# æ®µè½çº§æ£€ç´¢
# =====================
def ui_search_paragraph(query):
    emb = embed_text(query)
    results = search_paragraph(emb)

    if not results or not results.get("metadatas") or not results["metadatas"]:
        return "âŒ æœªæ‰¾åˆ°ç›¸å…³æ®µè½"
    
    # ä½¿ç”¨å¤„ç†åçš„ç»“æœ
    if results.get("processed"):
        processed = results["processed"]
    else:
        # å¦‚æœæ²¡æœ‰å¤„ç†åçš„ç»“æœï¼Œä» metadatas ä¸­æå–
        processed = []
        for i, meta in enumerate(results["metadatas"][0]):
            para_id = 0
            if results.get("ids") and results["ids"][0]:
                id_str = results["ids"][0][i]
                if "_" in id_str:
                    try:
                        para_id = int(id_str.split("_")[-1])
                    except:
                        para_id = i
            processed.append({
                "paper": meta.get("paper", "unknown"),
                "para_id": para_id,
                "text": meta.get("text", "")
            })

    out = []
    for r in processed:
        out.append(
            f"ğŸ“„ {r['paper']} | æ®µè½ {r['para_id']}\n{r['text'][:300]}...\n"
        )
    return "\n".join(out)

# =====================
# å›¾åƒç®¡ç†
# =====================
def ui_add_image(img_path):
    if not img_path: return "âŒ è¯·ä¸Šä¼ å›¾ç‰‡"
    try:
        fname = os.path.basename(img_path)
        save_path = os.path.join(IMAGE_DIR, fname)
        if not os.path.exists(save_path):
            shutil.copy(img_path, save_path)
        
        # å†…éƒ¨ä¼šåŒæ—¶å¾€ä¸¤ä¸ªåº“é‡Œå­˜å‘é‡
        desc = add_image_embedding(iid=fname, image_path=os.path.abspath(save_path))
        return f"âœ… å·²æ·»åŠ å¹¶å®ŒæˆåŒè½¨ç´¢å¼•ï¼š{fname}\nğŸ“ AIæè¿°: {desc}"
    except Exception as e:
        return f"âŒ æ·»åŠ å¤±è´¥: {str(e)}"
    
from batch_add_images import batch_add_images # â­ ç¡®ä¿å¯¼å…¥äº†åˆšæ‰é‚£ä¸ªè„šæœ¬

def ui_batch_sync():
    """UI è°ƒç”¨çš„æ‰¹é‡åŒæ­¥å‡½æ•°"""
    try:
        # è°ƒç”¨ä½ åˆšæ‰å®šä¹‰çš„é€»è¾‘
        stats = batch_add_images()
        return f"âœ… æ‰¹é‡åŒæ­¥ä»»åŠ¡ç»“æŸï¼\n{stats}"
    except Exception as e:
        return f"âŒ æ‰¹é‡åŒæ­¥å‡ºé”™: {str(e)}"

# =====================
# æ–‡å­—æœå›¾
# =====================

def ui_search_image(query, threshold, top_k, use_rerank):
    if not query.strip(): return "âŒ è¯·è¾“å…¥æœç´¢è¯", []
    if image_text_col.count() == 0: return "âŒ æ•°æ®åº“ä¸ºç©º", []

    # 1. è§£ææ—¶é—´èŒƒå›´ (DeepSeek è§£æ)
    time_range = tp.extract_time_constraints(query)
    start, end = time_range.get("start_date"), time_range.get("end_date")
    
    # 2. è¯­ä¹‰å‰¥ç¦» (æ ¸å¼¹çº§æ¸…æ´—ï¼šå‰¥ç¦»æ—¶é—´å™ªå£°ï¼Œæçº¯ä¸»ä½“)
    clean_query = query
    # [1] æ‹†é™¤å¹´ä»½ã€æœˆæ—¥ã€ç‰¹å®šè¿è¯
    clean_query = re.sub(r'(19[7-9]\d|20[0-2][0-7])å¹´?', '', clean_query)
    clean_query = re.sub(r'\d{1,2}æœˆ(\d{1,2}[æ—¥å·]?)?', '', clean_query)
    clean_query = re.sub(r'(å¹´çš„|æœˆçš„|é‚£å¼ |é‚£äº›|çš„ç…§ç‰‡|çš„å›¾ç‰‡|é‚£åª|é‚£æ¡|é‡Œçš„)', '', clean_query)
    # [2] æ‹†é™¤å­£èŠ‚å’Œç›¸å¯¹è¯
    noise_words = ["æ˜¥å¤©", "å¤å¤©", "ç§‹å¤©", "å†¬å¤©", "å»å¹´", "å‰å¹´", "ä»Šå¹´", "ä»¥å‰", "ä»¥å", "æœ€è¿‘"]
    for word in noise_words:
        clean_query = clean_query.replace(word, "")
    # [3] æœ€ç»ˆä¿®æ•´
    clean_query = clean_query.replace("çš„", "").strip()

    # â­ å®šä¹‰å…³é”®å˜é‡ï¼Œé˜²æ­¢åç»­æŠ¥é”™
    is_pure_time_query = (len(clean_query) == 0)
    # â­ è¡¥ä¸Š keywordsï¼šå°†æ´—å¹²å‡€çš„è¯­ä¹‰è¯æ‹†æˆåˆ—è¡¨ç”¨äºå¥–åŠ±æœºåˆ¶
    keywords = [k for k in re.split(r'[,ï¼Œ\s]+', clean_query) if len(k) > 0]

    # 3. å‘é‡æ£€ç´¢ (æµ·é€‰é˜¶æ®µï¼šæ‹¿ 20 æ¡ï¼Œä¸ºç²¾æ’ç•™ç©ºé—´)
    search_prompt = f"ä¸ºæŸ¥è¯¢ç¼–å†™æ£€ç´¢æè¿°ï¼š{clean_query}" if not is_pure_time_query else "ç…§ç‰‡"
    q_emb = embed_text(search_prompt) 
    hits = search_image_text(q_emb, top_k=20, date_filter=time_range)
    
    # --- é˜¶æ®µä¸€ï¼šç‰¹å¾æ³¨æ„åŠ›å¢å¼º (æ‰“æŠ˜é€»è¾‘) ---
    processed_hits = []
    for h in hits:
        d = h["distance"]
        desc = h["description"]
        
        # è®¡ç®—å…³é”®è¯å‘½ä¸­æ¬¡æ•°
        match_count = sum(1 for kw in keywords if kw in desc)
        is_boosted = False
        if not is_pure_time_query and match_count > 0:
            # å‘½ä¸­å³æ‰“æŠ˜ï¼Œæœ€é«˜æ‰“ 5 æŠ˜
            bonus = min(0.5, 0.3 + (match_count - 1) * 0.1)
            d = d * (1.0 - bonus)
            is_boosted = True
        
        h["final_dist"] = d  # è®°å½•è®¡ç®—åçš„è·ç¦»
        h["is_boosted"] = is_boosted
        
        # åˆå§‹è·ç¦»è¿‡æ»¤ (æ ¹æ®é˜ˆå€¼æ‹¦æˆª)
        if not is_pure_time_query and d > threshold:
            continue
        processed_hits.append(h)

    # æŒ‰å¢å¼ºåçš„è·ç¦»é‡æ–°æ’é˜Ÿ
    processed_hits = sorted(processed_hits, key=lambda x: x["final_dist"])

    # --- é˜¶æ®µäºŒï¼šçº§è”ç²¾æ’ (Cascaded Reranking) ---
    final_hits = []
    if use_rerank and not is_pure_time_query and processed_hits:
        # ğŸš€ 3.1 æ–‡æœ¬åˆç­› (DeepSeek å¤„ç†æè¿°å…ƒæ•°æ®)
        candidates = [{"id": i, "description": h["description"]} for i, h in enumerate(processed_hits)]
        refined_list = llm.filter_by_text(query, candidates)
        
        # ğŸš€ 3.2 è§†è§‰ç»ˆå®¡ (Qwen-VL åƒç´ çº§å¤æ ¸)
        for cand in refined_list:
            hit_data = processed_hits[cand["id"]]
            if llm.verify_image_content(hit_data["path"], query):
                final_hits.append(hit_data)
    else:
        # æœªå¼€å¯ç²¾æ’ï¼Œå– Top-K ç»“æœ
        final_hits = processed_hits[:int(top_k)]

    # 4. ç»“æœåŒ…è£…å±•ç¤º (å‰ç«¯ Gradio æ¸²æŸ“)
    imgs, info = [], []
    info.append(f"ğŸ” è¯­ä¹‰è¯: '{clean_query or 'ç©º'}' | ğŸ“… çº¦æŸ: {start or 'ä¸é™'} âœ {end or 'ä¸é™'}\n")

    for h in final_hits:
        if os.path.exists(h["path"]):
            imgs.append(Image.open(h["path"]))
            d = h["final_dist"]
            # çº¯æ—¶é—´æŸ¥è¯¢åŒ¹é…åº¦é»˜è®¤ 100%ï¼Œå¦åˆ™æ ¹æ® dist æ¢ç®—
            similarity = 100.0 if is_pure_time_query else max(0, (2 - d) / 2 * 100)
            
            raw_date = str(h.get("date", "æœªçŸ¥"))
            display_date = f"{raw_date[:4]}-{raw_date[4:6]}-{raw_date[6:]}" if len(raw_date)==8 else raw_date
            boost_tag = "ğŸš€ [å·²å¢å¼º]" if h["is_boosted"] else ""
            
            info.append(f"ğŸ¯ dist: {d:.3f} {boost_tag} | åŒ¹é…åº¦: {similarity:.1f}% | ğŸ“… {display_date}\nğŸ“ {h['description']}\n")
            
    return "\n".join(info), imgs

# =====================
# ä»¥å›¾æœå›¾
# =====================

def ui_image_to_image(input_img, threshold, top_k): # â­ ç¡®è®¤è¿™é‡Œä¹Ÿæ˜¯ 3 ä¸ªå‚æ•°
    if input_img is None: return "âŒ æœªä¸Šä¼ ", []
    if image_visual_col.count() == 0: return "âŒ æ•°æ®åº“ä¸ºç©º", []
    
    try:
        img = Image.open(input_img).convert("RGB") if isinstance(input_img, str) else input_img
        q_emb = embed_image(img)
        hits = search_image_visual(q_emb, top_k=int(top_k), date_filter=None)
        
        info = [f"ğŸ” è§†è§‰æ£€ç´¢ç»“æœ (Top-{top_k}):"]
        imgs = []
        for h in hits:
            if os.path.exists(h['path']):
                imgs.append(Image.open(h['path']))
                info.append(f"{'âœ…' if h['distance']<threshold else 'âš ï¸'} {os.path.basename(h['path'])} | d={h['distance']:.3f}")
        return "\n".join(info), imgs
    except Exception as e: return f"âŒ å¤±è´¥: {e}", []
    
# =====================
# Gradio UI å¸ƒå±€
# =====================
with gr.Blocks(title="æœ¬åœ°å¤šæ¨¡æ€ AI åŠ©æ‰‹") as demo:
    gr.Markdown("# ğŸ“š æœ¬åœ°å¤šæ¨¡æ€ AI æ™ºèƒ½åŠ©æ‰‹ (æœ¬åœ°ç‰ˆ)")

    with gr.Tab("ğŸ“„ æ·»åŠ è®ºæ–‡"):
        pdf = gr.File(file_types=[".pdf"], label="ä¸Šä¼  PDF")
        topics = gr.Textbox(label="å€™é€‰ä¸»é¢˜ï¼ˆé€—å·åˆ†éš”ï¼‰", value="CV,NLP,RL")
        btn = gr.Button("æ·»åŠ è®ºæ–‡")
        out = gr.Textbox(lines=4, max_lines=15)
        btn.click(ui_add_paper, [pdf, topics], out)

    with gr.Tab("ğŸ” è®ºæ–‡æœç´¢"):
        q = gr.Textbox(label="æŸ¥è¯¢")
        btn2 = gr.Button("æœç´¢")
        out2 = gr.Textbox(lines=8, max_lines=30)
        btn2.click(ui_search_paper, q, out2)

    with gr.Tab("ğŸ§© æ®µè½æ£€ç´¢"):
        q3 = gr.Textbox(label="æŸ¥è¯¢æ®µè½")
        btn3 = gr.Button("æœç´¢")
        out3 = gr.Textbox(lines=12, max_lines=30)
        btn3.click(ui_search_paragraph, q3, out3)

    with gr.Tab("ğŸ–¼ï¸ æ·»åŠ å›¾ç‰‡"):
        with gr.Row():
            img_in = gr.File(label="æ·»åŠ æ–°å›¾")
            btn_add = gr.Button("å¼€å§‹ç´¢å¼•")
        out_add = gr.Textbox(label="çŠ¶æ€")
        btn_add.click(ui_add_image, img_in, out_add)
    
    with gr.Tab("ğŸ“ æ‰¹é‡ç®¡ç†"):
        gr.Markdown("### ğŸ› ï¸ æœ¬åœ°æ–‡ä»¶å¤¹åŒæ­¥\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œè‡ªåŠ¨æ‰«æ `IMAGE_DIR` ç›®å½•ä¸‹çš„æ–°ç…§ç‰‡ã€‚")
        batch_btn = gr.Button("ğŸ”„ ç«‹å³åŒæ­¥æœ¬åœ°æ–‡ä»¶å¤¹", variant="secondary")
        batch_output = gr.Textbox(label="åŒæ­¥ç»“æœ", lines=3)
        
        # ç»‘å®šç‚¹å‡»äº‹ä»¶
        batch_btn.click(ui_batch_sync, inputs=[], outputs=[batch_output])

    with gr.Tab("ğŸ§  ä»¥æ–‡æœå›¾"):
        with gr.Row():
            q_txt = gr.Textbox(label="è¾“å…¥æè¿°è¯", placeholder="ä¾‹å¦‚ï¼šå»å¹´åœ¨æµ·è¾¹æ‹çš„ç…§ç‰‡")
        
        with gr.Row():
            t_txt = gr.Slider(0.1, 1.5, value=1.0, label="è¯­ä¹‰é˜ˆå€¼ (distè¶Šå°è¶Šå‡†)")
            k_txt = gr.Slider(1, 20, value=8, step=1, label="å±•ç¤ºæ•°é‡ (Top-K)")
            # â­ 1. æ–°å¢è¿™ä¸ªå¤é€‰æ¡†
            rerank_ch = gr.Checkbox(label="å¯ç”¨Rerank", value=False) 

        btn_txt = gr.Button("ğŸ” å¼€å§‹æœç´¢", variant="primary")
        info_txt = gr.Textbox(label="ç»“æœè¯¦æƒ…")
        gal_txt = gr.Gallery(columns=4, label="åŒ¹é…ç…§ç‰‡")

        btn_txt.click(
            ui_search_image, 
            inputs=[q_txt, t_txt, k_txt, rerank_ch], 
            outputs=[info_txt, gal_txt]
        )

    with gr.Tab("ğŸ“¸ ä»¥å›¾æœå›¾"):
        q_img = gr.Image(label="æºå›¾", type="filepath")
        with gr.Row():
            t_img = gr.Slider(0.1, 1.0, value=0.35, label="ç›¸ä¼¼åº¦é˜ˆå€¼")
            k_img = gr.Slider(1, 20, value=5, step=1, label="å±•ç¤ºæ•°é‡") # â­ è¿™æ˜¯å¦ä¸€ä¸ªæ»‘å—
        btn_img = gr.Button("ğŸ–¼ï¸ æ‰§è¡ŒåŒ¹é…")
        info_img = gr.Textbox(label="åŒ¹é…è¯¦æƒ…")
        gal_img = gr.Gallery(columns=4)
        # â­ å…³é”®ä¿®æ­£ï¼šç¡®ä¿ inputs é‡Œçš„å‚æ•°æ˜¯ 3 ä¸ª
        btn_img.click(ui_image_to_image, [q_img, t_img, k_img], [info_img, gal_img])

demo.launch(server_name="0.0.0.0", server_port=7860)